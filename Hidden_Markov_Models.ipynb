{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#We will model a wheather system, thst will predict the temperature on each day given the following information:\n",
        "\n",
        "1. Cold days are encoded by 0, hot days encoded by 1\n",
        "2. The first day in our sequence has 80% chance of being cold\n",
        "3. A cold day has a 30% chance of being followed by a hot day\n",
        "4. A hot day has 20% chance of being followed by a cold day\n",
        "5. On each day the temperature is normmally distributed, with mean and standard deviation 0 and 5 on a cold day and mean and standard deviation 15 and 10 on a hot day"
      ],
      "metadata": {
        "id": "Oo00rvusOsR0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_probability as tfp #separate module from tensorflow that deals with probability\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "8dCatlHxMHkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfd = tfp.distributions\n",
        "initial_distribution = tfd.Categorical(probs=[0.8, 0.2]) #80% cold, 20% hot  Note: 2 states = 2 probabilities\n",
        "transition_distribution = tfd.Categorical(probs=[[0.7, 0.3],\n",
        "                                                [0.2, 0.8]]) #70% cold, 30 hot and 20% cold, 80% hot\n",
        "observation_distribution = tfd.Normal(loc=[0., 15.], scale=[5., 10.]) #Point 5 above, loc = mean, scale = std deviation, we use dot bcs we want float values\n",
        "\n"
      ],
      "metadata": {
        "id": "0v_ag35_MHi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Building a model\n",
        "model = tfd.HiddenMarkovModel(\n",
        "    initial_distribution = initial_distribution,\n",
        "    transition_distribution = transition_distribution,\n",
        "    observation_distribution = observation_distribution,\n",
        "    num_steps = 7 #How many times we are going to step through this cycle and run the model in our case it is a number of days\n",
        ")"
      ],
      "metadata": {
        "id": "0u4v_DjaMHhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean = model.mean() #mean = partially defined tensor\n",
        "\n",
        "with tf.compat.v1.Session() as sees:\n",
        "  print(mean.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCoHVR-EMHfM",
        "outputId": "51198001-075b-4d1f-e369-602583c796d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3.        5.9999995 7.4999995 8.25      8.625001  8.812501  8.90625  ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Conclusion\n",
        "In Hidden Markov Models, the prediction is based onprobability distribution rather than data itself. Even if you rerun the building of a model, the final output will be the same, because calculationa made on the probability, and there is no training at all."
      ],
      "metadata": {
        "id": "0tU3peJR1bjr"
      }
    }
  ]
}